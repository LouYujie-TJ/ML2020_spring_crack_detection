{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"train_segment_crack_unet.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Je-jZlZw98JR","colab_type":"code","outputId":"4f67bbdb-8eb4-4a3f-d83f-88d28babaa04","executionInfo":{"status":"ok","timestamp":1591453186969,"user_tz":-480,"elapsed":2366,"user":{"displayName":"Yunpeng Deng","photoUrl":"","userId":"11828948728824100341"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["!nvidia-smi # 查看GPU信息"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Jun  6 14:19:46 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   74C    P0    86W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ErvIucUC98Jd","colab_type":"code","outputId":"d38daf17-c991-4db4-b756-2e647c1a7885","executionInfo":{"status":"ok","timestamp":1591453188246,"user_tz":-480,"elapsed":542,"user":{"displayName":"Yunpeng Deng","photoUrl":"","userId":"11828948728824100341"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GSlUNuJi98Jj","colab_type":"code","outputId":"ba66786a-0b29-467e-efdf-e3dad15fe41a","executionInfo":{"status":"ok","timestamp":1591453194106,"user_tz":-480,"elapsed":767,"user":{"displayName":"Yunpeng Deng","photoUrl":"","userId":"11828948728824100341"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 进入需要训练项目的文件夹\n","%cd /content/drive/My Drive/Colab Notebooks/ML2020_spring_crack_detection/CrackU-Net-cross-entropy"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/ML2020_spring_crack_detection/CrackU-Net-cross-entropy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b0c0pIzFBn75","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"e48f7d13-75e2-4640-92f8-dd7afa72689b","executionInfo":{"status":"ok","timestamp":1591453199302,"user_tz":-480,"elapsed":3824,"user":{"displayName":"Yunpeng Deng","photoUrl":"","userId":"11828948728824100341"}}},"source":["!pip install xlutils"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xlutils in /usr/local/lib/python3.6/dist-packages (2.0.0)\n","Requirement already satisfied: xlrd>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from xlutils) (1.1.0)\n","Requirement already satisfied: xlwt>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from xlutils) (1.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBSpRY0i98Ju","colab_type":"code","colab":{}},"source":["from models_crack_unet import SegmentNet, weights_init_normal\n","from dataset_crack_unet import CFDDataset\n","\n","import torch.nn as nn\n","import torch\n","\n","from torchvision import datasets\n","from torchvision.utils import save_image\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","\n","import os\n","import sys\n","import argparse\n","import time\n","import PIL.Image as Image\n","\n","import numpy as np\n","\n","import xlwt\n","import xlrd\n","from xlutils.copy import copy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KrIvveOM98Jz","colab_type":"code","outputId":"2322ba0a-4d7f-4706-e43c-f662d8ece506","executionInfo":{"status":"ok","timestamp":1591453512441,"user_tz":-480,"elapsed":1387,"user":{"displayName":"Yunpeng Deng","photoUrl":"","userId":"11828948728824100341"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# 在ipynb文件中，parse的创建用函数来创建\n","# 直接用parser=parser = argparse.ArgumentParser() 来创建之后调用会报错\n","\n","def get_arguments():\n","    parser = argparse.ArgumentParser()\n","\n","    parser.add_argument(\"--cuda\", type=bool, default=True, help=\"number of gpu\")\n","    parser.add_argument(\"--gpu_num\", type=int, default=1, help=\"number of gpu\")\n","    parser.add_argument(\"--worker_num\", type=int, default=0, help=\"number of input workers\") # 只有一个GPU,default=0表示单进程加载\n","    parser.add_argument(\"--batch_size\", type=int, default=4, help=\"batch size of input\")\n","    parser.add_argument(\"--lr\", type=float, default=0.0005, help=\"adam: learning rate\")\n","    parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n","    parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n","\n","    parser.add_argument(\"--begin_epoch\", type=int, default=0, help=\"begin_epoch\")\n","    parser.add_argument(\"--end_epoch\", type=int, default=101, help=\"end_epoch\")\n","\n","    parser.add_argument(\"--need_test\", type=bool, default=True, help=\"need to test\")\n","    parser.add_argument(\"--test_interval\", type=int, default=2, help=\"interval of test\")\n","    parser.add_argument(\"--need_save\", type=bool, default=True, help=\"need to save\")\n","    parser.add_argument(\"--save_interval\", type=int, default=2, help=\"interval of save weights\")\n","\n","\n","    parser.add_argument(\"--img_width\", type=int, default=480, help=\"size of image width\")\n","    parser.add_argument(\"--img_height\", type=int, default=320, help=\"size of image height\")\n","    \n","    return parser.parse_args(args=[])\n","\n","opt = get_arguments()\n","\n","print(opt)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Namespace(b1=0.5, b2=0.999, batch_size=4, begin_epoch=0, cuda=True, end_epoch=101, gpu_num=1, img_height=320, img_width=480, lr=0.0005, need_save=True, need_test=True, save_interval=2, test_interval=2, worker_num=0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mnHkdMxx98J7","colab_type":"code","colab":{}},"source":["dataSetRoot = \"../Data\" "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lrEnbFb98KA","colab_type":"code","colab":{}},"source":["# 建立网络\n","segment_net = SegmentNet(init_weights=True)\n","\n","# 选择二分类交叉熵损失函数\n","criterion_segment  = torch.nn.BCELoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqkKSXpG98KF","colab_type":"code","colab":{}},"source":["# 选择训练环境和参数\n","if opt.cuda:\n","    segment_net = segment_net.cuda()\n","    criterion_segment.cuda()\n","\n","if opt.gpu_num > 1:\n","    segment_net = torch.nn.DataParallel(segment_net, device_ids=list(range(opt.gpu_num)))\n","\n","if opt.begin_epoch != 0:\n","    # 加载前期训练的模型\n","    segment_net.load_state_dict(torch.load(\"./saved_models/segment_net_%d.pth\" % (opt.begin_epoch)))\n","else:\n","    # 初始化权重\n","    segment_net.apply(weights_init_normal)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P7x5y3H098KK","colab_type":"code","colab":{}},"source":["# 选择Adam优化器\n","optimizer_seg = torch.optim.Adam(segment_net.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cys8eeMh98KP","colab_type":"code","colab":{}},"source":["# 对原始数据和真实值进行一定前期处理，方便后续训练\n","transforms_ = transforms.Compose([\n","    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n","    transforms.ToTensor()\n","])\n","\n","transforms_mask = transforms.Compose([\n","    transforms.Resize((opt.img_height, opt.img_width)), \n","    transforms.ToTensor()\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"STNFdFYe98KU","colab_type":"code","colab":{}},"source":["# 加载训练集和测试集\n","trainCFDloader = DataLoader(\n","    CFDDataset(dataSetRoot, transforms_=transforms_, transforms_mask= transforms_mask, subFold=\"CFD\", isTrain=True),\n","    batch_size=opt.batch_size,\n","    shuffle=True,\n","    num_workers=opt.worker_num,\n",")\n","\n","testloader = DataLoader(\n","    CFDDataset(dataSetRoot, transforms_=transforms_, transforms_mask= transforms_mask,  subFold=\"CFD/cfd_TEST\", isTrain=True),\n","    batch_size=1,\n","    shuffle=False,\n","    num_workers=opt.worker_num\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"msQjqbFDsBsu","colab_type":"code","colab":{}},"source":["# 定义对输出结果进行阈值化处理的函数，将小于阈值的计算为0，大于阈值的计算为1，在图像中像素为1的点为白色，为0的点为黑色\n","def data_threshold(data, threshold):\n","    threshold = torch.Tensor([threshold]).cuda()\n","    data_target = torch.Tensor([i//threshold for i in data]).cuda()\n","    return data_target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJPMOhJRrdra","colab_type":"code","colab":{}},"source":["# 获取训练之后的 accuracy, precision , recall ,F1评价指标\n","# mask是真实值，data是预测值\n","def evaluate_metric(mask, data):\n","    \n","    count_TP, count_FN, count_FP, count_TN = 0, 0, 0, 0\n","    \n","    for i in range(len(mask)):\n","        if mask[i]==1 and data[i]==1:\n","            count_TP += 1  \n","        elif mask[i]==1:\n","            count_FN += 1      \n","        elif data[i]==1:\n","            count_FP += 1      \n","        else:\n","            count_TN += 1\n","\n","    count = count_TP + count_FN + count_FP +count_TN\n","    \n","    # 准确率\n","    accuracy = (count_TP+count_TN)/count \n","    # 精准率\n","    precision = count_TP / (count_TP + count_FP) \n","    # 查全率\n","    recall = count_TP / (count_TP + count_FN)\n","    # F1分\n","    F1 = 2*count_TP/(2*count_TP + count_FP + count_FN)\n","    \n","    return accuracy, precision, recall, F1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nlxv5rtP-EyV","colab_type":"code","colab":{}},"source":["# 将训练过程的需要保存的数据保存到xls文件中\n","# 创建一个workbook，设置编码\n","workbook = xlwt.Workbook(encoding = 'utf-8')\n","\n","#---------------------写入训练过程的epoch, loss, accuracy------------------\n","# 创建一个worksheet\n","worksheet = workbook.add_sheet('sheet1')\n","worksheet.write(0, 0, 'epoch')\n","worksheet.write(0, 1, 'loss')\n","worksheet.write(0, 2, 'accuracy')\n","\n","#---------------------写入测试过程的epoch, loss, accuracy------------------\n","worksheet = workbook.add_sheet('sheet2')\n","worksheet.write(0, 0, 'epoch')\n","worksheet.write(0, 1, 'loss')\n","worksheet.write(0, 2, 'accuracy')\n","                \n","#---------------------写入测试过程的epoch, accuracy, precision, recall, F1------------------                \n","worksheet = workbook.add_sheet('sheet3')\n","worksheet.write(0, 0, 'epoch')\n","worksheet.write(0, 1, 'accuracy')\n","worksheet.write(0, 2, 'precision')\n","worksheet.write(0, 3, 'recall')\n","worksheet.write(0, 4, 'F1')\n","\n","# 保存\n","workbook.save('evaluate_data.xls')\n","\n","def write_excel_xls_append(path, value, sheet_num):\n","  index = len(value)  # 获取需要写入数据的行数\n","  workbook = xlrd.open_workbook(path)            # 打开工作簿\n","  sheets = workbook.sheet_names()                # 获取工作簿中的所有表格\n","  worksheet = workbook.sheet_by_name(sheets[sheet_num])  # 获取工作簿中所有表格中的的第一个表格\n","  rows_old = worksheet.nrows                 # 获取表格中已存在的数据的行数\n","  new_workbook = copy(workbook)                # 将xlrd对象拷贝转化为xlwt对象\n","  new_worksheet = new_workbook.get_sheet(sheet_num)      # 获取转化后工作簿中的第sheet_num个表格\n","  \n","  for i in range(0, index):\n","      new_worksheet.write(rows_old, i, value[i])  # 追加写入数据\n","  new_workbook.save(path)  # 保存工作簿\n","  print(\"xls格式表格[追加]写入数据成功！\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AljlVei798Kd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"d28304b1-b924-4ef1-d128-77e5fee68c89"},"source":["for epoch in range(opt.begin_epoch, opt.end_epoch):\n","\n","  iterCFD = trainCFDloader.__iter__()\n","\n","  lenNum = len(trainCFDloader)\n","\n","  segment_net.train()\n","\n","  # -----------------------------------------------------------------------------\n","  # 开始训练\n","  # 记录每一个epoch的总损失和总精度\n","  train_loss_sum, train_acc_sum, batch_count = 0.0, 0.0, 0.0\n","\n","  for i in range(0, lenNum):\n","      \n","    batchData = iterCFD.__next__()\n","\n","    if opt.cuda:\n","        img = batchData[\"img\"].cuda()\n","        mask = batchData[\"mask\"].cuda()\n","    else:\n","        img = batchData[\"img\"]\n","        mask = batchData[\"mask\"]\n","\n","    optimizer_seg.zero_grad()\n","\n","    rst = segment_net(img)\n","    seg = rst[\"seg\"]\n","\n","    # 计算训练过程的损失loss\n","    loss_seg = criterion_segment(seg, mask)\n","    loss_seg.backward()\n","    optimizer_seg.step()\n","\n","    train_loss_sum += loss_seg.item() \n","    \n","    # 计算训练过程的accuracy\n","    net_seg = data_threshold(seg.clone().flatten(), 0.6)    # 预测值\n","    mask_seg = mask.clone().flatten()              # 真实值\n","    \n","    # 对每个像素点的值进行比较，相同的点计入right_seg \n","    right_seg = torch.eq(net_seg, mask_seg).sum().float().item()\n","    total_num = float(mask.clone().flatten().size()[0])\n","    \n","    batch_acc = right_seg/total_num\n","    train_acc_sum += batch_acc\n","    \n","    batch_count += 1\n","\n","    # 输出每个epoch之中每个batch的信息\n","    print(\"[Epocn:{0}],[batch_count:{1}],[loss:{2:.6f}],[accuracy:{3:.6f}]\".format(epoch, batch_count, loss_seg.item(), batch_acc))\n","    \n","  # 输出训练过程每个epoch平均的loss和accuracy\n","  print(\"[Epoch {0}/{1}], [loss:{2:.6f}], accuracy:{3:.6f}]\".format(epoch, opt.end_epoch, train_loss_sum/batch_count, train_acc_sum/batch_count))\n","    \n","  # 将上述epoch, loss, accuracy数据写入xls文件\n","  print(\"------------------------------------------------------------------------------------------\")\n","  print(\"开始写入训练过程的epoch, loss, accuracy\")\n","  train_xls_value = [epoch, train_loss_sum/batch_count, train_acc_sum/batch_count]\n","  write_excel_xls_append(\"evaluate_data.xls\", train_xls_value, 0)\n","  print(\"------------------------------------------------------------------------------------------\")\n","\n","\n","  # -----------------------------------------------------------------------------\n","  # 以一定周期保存训练之后的模型\n","  if opt.need_save and epoch % opt.save_interval == 0 and epoch >= opt.save_interval:\n","\n","    save_path_str = \"./saved_models\"\n","    if os.path.exists(save_path_str) == False:\n","        os.makedirs(save_path_str, exist_ok=True)\n","\n","    torch.save(segment_net.state_dict(), \"%s/segment_net_%d.pth\" % (save_path_str, epoch))\n","    print(\"------------------------------------------------------------------------------------------\")\n","    print(\"save weights ! epoch = %d\" %epoch)\n","    print(\"------------------------------------------------------------------------------------------\")\n","    pass\n","    \n","\n","  # -----------------------------------------------------------------------------\n","  # 对模型进行测试，并保存结果\n","  if opt.need_test and epoch % opt.test_interval == 0 and epoch >= opt.test_interval:\n","\n","    test_loss_sum, test_acc_sum, batch_count = 0.0, 0.0, 0.0\n","    result_evaluate_epoch = np.array([0.0, 0.0, 0.0, 0.0])\n","\n","    for i, testBatch in enumerate(testloader):\n","      imgTest = testBatch[\"img\"].cuda()\n","      t1 = time.time()\n","      rstTest = segment_net(imgTest)\n","      t2 = time.time()\n","\n","      # 计算测试过程的损失loss\n","      mask = testBatch[\"mask\"].cuda()\n","      loss_test = criterion_segment(rstTest[\"seg\"], mask)\n","\n","      test_loss_sum += loss_test.item()\n","\n","      # 计算测试过程的accuracy\n","      net_seg = data_threshold(rstTest[\"seg\"].clone().flatten(), 0.6)  # 预测值\n","      mask_seg = mask.clone().flatten()                  # 真实值\n","      \n","      # 对每个像素点的值进行比较，相同的点计入right_seg \n","      right_seg = torch.eq(net_seg, mask_seg).sum().float().item()\n","      total_num = float(mask.clone().flatten().size()[0])\n","      \n","      batch_acc = right_seg/total_num\n","      test_acc_sum += batch_acc\n","      \n","      batch_count += 1\n","\n","      # 对一个batch测试结果进行综合评估，并进行累加，方便后续保存\n","      result_evaluate_batch = np.array(list(evaluate_metric(mask_seg, net_seg)))\n","      result_evaluate_epoch += result_evaluate_batch\n","      \n","      # 对保存的图片进行阈值化处理\n","      seg_shape = rstTest[\"seg\"].data.shape\n","      segTest_flatten = data_threshold(rstTest[\"seg\"].flatten(), 0.6)\n","      segTest = segTest_flatten.reshape(seg_shape[0], seg_shape[1], seg_shape[2], seg_shape[3])\n","\n","      # 建立文件的保存路径\n","      save_path_str = \"./testResultSeg/epoch_%d\"%(epoch)\n","      if os.path.exists(save_path_str) == False:\n","          os.makedirs(save_path_str, exist_ok=True)\n","\n","      # 输出文件的保存信息\n","      print(\"processing image NO %d, time comsuption %fs\"%(i, t2 - t1))\n","      save_image(imgTest.data, \"%s/img_%d.jpg\"% (save_path_str, i))\n","      save_image(segTest.data, \"%s/img_%d_seg.jpg\"% (save_path_str, i))\n","\n","    # 将上述测试过程的评估参数acc,precision,recall和F1分数进行保存\n","    print(\"------------------------------------------------------------------------------------------\")\n","    print(\"开始写入评估参数\")\n","    result_evaluate_epoch = result_evaluate_epoch/np.array([batch_count])\n","    test_xls_metric = [epoch] + list(result_evaluate_epoch)\n","    write_excel_xls_append(\"evaluate_data.xls\", test_xls_metric, 2)\n","    print(\"------------------------------------------------------------------------------------------\")\n","    \n","    # 输出测试过程每个epoch平均的loss和accuracy\n","    print(\"------------------------------------------------------------------------------------------\")\n","    print(\"[Epoch {0}/{1}], [loss:{2:.6f}], accuracy:{3:.6f}]\".format(epoch, opt.end_epoch, test_loss_sum/batch_count, test_acc_sum/batch_count))\n","    print(\"------------------------------------------------------------------------------------------\")\n","    \n","    # 将上述epoch, loss, accuracy数据写入xls文件\n","    print(\"------------------------------------------------------------------------------------------\")\n","    print(\"开始写入测试过程的epoch, loss, accuracy\")\n","    test_xls_value = [epoch, test_loss_sum/batch_count, test_acc_sum/batch_count]\n","    write_excel_xls_append(\"evaluate_data.xls\", test_xls_value, 1)\n","    print(\"------------------------------------------------------------------------------------------\")\n","\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Epocn:0],[batch_count:1.0],[loss:0.660183],[accuracy:0.983200]\n","[Epocn:0],[batch_count:2.0],[loss:0.698520],[accuracy:0.958566]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9hJjYZjs2W38","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}